{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be41c046",
   "metadata": {},
   "source": [
    "# EEG-BCI Pipeline Documentation & Developer Guide\n",
    "\n",
    "This notebook documents a full EEG-based Brain–Computer Interface (BCI) pipeline that connects to an OpenBCI Cyton board and uses real-time neural activity to control a wheelchair assembly. It explains how to acquire EEG data, preprocess and train motor imagery models, and deploy them in a live control loop that translates user intent into motion commands. The goal is both to serve as technical documentation and as a step-by-step guide for developers who need to run, modify, or extend the system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e2abf2",
   "metadata": {},
   "source": [
    "# 1. Data Acquisition (from Cyton)\n",
    "\n",
    "This script collects EEG trials from the OpenBCI Cyton board and saves them into organized dataset folders for model training. Each trial corresponds to a single mental task (e.g., imagining moving the left or right hand)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7c7965-a4c0-48ca-b92b-981a28c99618",
   "metadata": {},
   "source": [
    "# Imports and Functions\n",
    "- BrainFlow API: handles connection to the Cyton board.\n",
    "- NumPy: stores EEG samples in .npy format.\n",
    "- time/os: timestamps and directory management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b8469f-b473-4db9-a7ba-429425236415",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainflow import BoardShim, BrainFlowInputParams, BoardIds\n",
    "import numpy as np\n",
    "import time, os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ae928a-9488-4f6c-abe1-e3abd1570e05",
   "metadata": {},
   "source": [
    "- Defines how long each trial lasts, how many samples to expect, and where to save the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0d2548-fac1-4600-9417-641531f79a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIAL_DURATION = 1          # Seconds per trial\n",
    "SAMPLES_PER_SEC = 250       # Cyton sample rate\n",
    "NUM_TRIALS = 100            # Trials per class\n",
    "DATASET_ROOT = r\"...\\datasets\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277e144b-6d5e-40f7-aba7-20a22220af70",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "- Ensures the folder structure exists (e.g., motor/left/).\n",
    "- Saves each trial as a timestamped .npy file.\n",
    "- Prints confirmation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a2a9c7-a648-4bac-9d8d-319ba12dad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_trial(data, label, region_dir):\n",
    "    os.makedirs(os.path.join(region_dir, label), exist_ok=True)\n",
    "    filename = os.path.join(region_dir, label, f\"{int(time.time()*1000)}.npy\")\n",
    "    np.save(filename, data)\n",
    "    print(f\"Saved {data.shape} samples to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e248b9-1a8c-467b-9969-a7a20aeea64c",
   "metadata": {},
   "source": [
    "# Board Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41f7d29-9873-4fb4-a460-4d847fbdfc8e",
   "metadata": {},
   "source": [
    "- Connects to the Cyton board on the specified COM port.\n",
    "- Starts the EEG data stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bab055-2d08-46f7-9455-e700c8c278eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = BrainFlowInputParams()\n",
    "params.serial_port = \"COM3\"\n",
    "board = BoardShim(BoardIds.CYTON_BOARD.value, params)\n",
    "board.prepare_session()\n",
    "board.start_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea91606-7501-4f9e-8dc6-8db7dc7df049",
   "metadata": {},
   "source": [
    "- Each subject gets their own dataset folder.\n",
    "    - Example:\n",
    "    - datasets/Grey/motor/left/\n",
    "    - datasets/Grey/motor/right/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed6e3b9-06e7-4968-9b97-1f28a47dba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = input(\"Enter patient name: \")\n",
    "root_dir = os.path.join(DATASET_ROOT, name)\n",
    "motor_dir = os.path.join(root_dir, \"motor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84833f18-dec0-4faf-9fe3-4a6797b118a9",
   "metadata": {},
   "source": [
    "- Selects all 8 Cyton EEG channels.\n",
    "- This preserves raw flexibility for future preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b24ac8-6cc2-4df7-8e81-01429b0ac301",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_channels = BoardShim.get_eeg_channels(BoardIds.CYTON_BOARD.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8166fde7-65ac-433e-b456-d6983a05d48a",
   "metadata": {},
   "source": [
    "# Trail Collection Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14983b55-898e-46cf-8206-8b04b842ef8e",
   "metadata": {},
   "source": [
    "How it works:\n",
    "- Prompts the user to perform the mental task.\n",
    "- Flushes the buffer to avoid stale samples.\n",
    "- Waits exactly TRIAL_DURATION seconds.\n",
    "- Pulls 250 fresh samples from all selected channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77962c6d-3ab9-4979-9761-e448cb784cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    motor_labels = [\"left\", \"right\"]\n",
    "    print(\"Get ready for EEG data collection...\")\n",
    "\n",
    "    for label in motor_labels:\n",
    "        print(f\"\\n--- Starting {NUM_TRIALS} {label.upper()} trials ---\")\n",
    "        for t in range(NUM_TRIALS):\n",
    "            # input(f\"Press Enter to start trial {t+1}/{NUM_TRIALS} ({label})\")\n",
    "            print(f\"Imagine moving your {label} hand for {TRIAL_DURATION} seconds...\")\n",
    "            board.get_board_data()  # flush\n",
    "            time.sleep(TRIAL_DURATION)\n",
    "            eeg_data = board.get_current_board_data(250)[selected_channels, :]\n",
    "\n",
    "            desired = SAMPLES_PER_SEC\n",
    "            current = eeg_data.shape[1]\n",
    "\n",
    "            if current > desired:\n",
    "                eeg_data = eeg_data[:, -desired:]  # crop extra\n",
    "            elif current < desired:\n",
    "                pad = np.tile(eeg_data[:, -1:], (1, desired - current))\n",
    "                eeg_data = np.concatenate((eeg_data, pad), axis=1)\n",
    "            \n",
    "            save_trial(eeg_data, label, motor_dir)\n",
    "\n",
    "finally:\n",
    "    board.stop_stream()\n",
    "    board.release_session()\n",
    "    print(\"\\nSession finished safely.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b988e896-80f1-4aa1-97a7-43550cbc4824",
   "metadata": {},
   "source": [
    "# 2. Inspect Raw Samples (Optional, Helpful for Toubleshooting)\n",
    "\n",
    "Change the sample data path to where your's are save to, to view it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dce636e-5d30-499a-80f5-a254bf1f5b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.load(\"datasets/name/motor/left/sample_001.npy\")\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "# TODO: Update these channels to the correct positions on the headset\n",
    "for i, label in enumerate([\"C3\", \"Cz\", \"C4\", \"CPz\", \"P3\", \"Pz\", \"P4\", \"jaw_connection\"]):\n",
    "    plt.plot(sample[i], label=label, alpha=0.8)\n",
    "\n",
    "plt.title(\"Raw Motor EEG Trial (8 channels)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7518eb15-0756-4c59-a1e1-2bf16fe1f602",
   "metadata": {},
   "source": [
    "# 3. Train a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab967b9-8ecd-4075-8ac5-db9a12fb6b7a",
   "metadata": {},
   "source": [
    "# Imports & Basic Setup\n",
    "prints if there are any GPUs the workstation can use for training the nerual network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8a0c15-5525-4ab6-8bbe-a31058d9ac78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from functions import split_data, standardize, load_data, preprocess_raw_eeg, ACTIONS\n",
    "from neural_nets import cris_net, res_net, TA_CSPNN, EEGNet\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available:\", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d6e7e5-ce9e-4f2b-b533-7b6bf312a2a9",
   "metadata": {},
   "source": [
    "# Fit & Save Function\n",
    "Saves the current model's validation and training is above 77% accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531ccbf8-5ea7-4195-8a69-acfa7a1f6047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_save(model, epochs, train_X, train_y, validation_X, validation_y, batch_size):\n",
    "    # fits the network epoch by epoch and saves only accurate models\n",
    "\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        history = model.fit(train_X, train_y, epochs=1, batch_size=batch_size,\n",
    "                            validation_data=(validation_X, validation_y))\n",
    "\n",
    "        train_acc.append(history.history[\"accuracy\"][-1])\n",
    "        train_loss.append(history.history[\"loss\"][-1])\n",
    "        val_acc.append(history.history[\"val_accuracy\"][-1])\n",
    "        val_loss.append(history.history[\"val_loss\"][-1])\n",
    "\n",
    "        MODEL_NAME = f\"models/Grey/{round(val_acc[-1] * 100, 2)}-{epoch}epoch-{int(time.time())}-loss-{round(val_loss[-1], 2)}.keras\"\n",
    "\n",
    "        if round(val_acc[-1] * 100, 4) >= 77 and round(train_acc[-1] * 100, 4) >= 77:\n",
    "            # saving & plotting only relevant models\n",
    "            model.save(MODEL_NAME)\n",
    "            print(\"saved: \", MODEL_NAME)\n",
    "\n",
    "            # Create combined plot with accuracy and loss\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "            # TODO: Only save this once training is over\n",
    "            \n",
    "            # Accuracy subplot\n",
    "            ax1.plot(np.arange(len(val_acc)), val_acc, label='val', linewidth=2)\n",
    "            ax1.plot(np.arange(len(train_acc)), train_acc, label='train', linewidth=2)\n",
    "            ax1.set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "            ax1.set_ylabel('Accuracy', fontsize=12)\n",
    "            ax1.set_xlabel('Epoch', fontsize=12)\n",
    "            ax1.legend(loc='lower right')\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Loss subplot\n",
    "            ax2.plot(np.arange(len(val_loss)), val_loss, label='val', linewidth=2)\n",
    "            ax2.plot(np.arange(len(train_loss)), train_loss, label='train', linewidth=2)\n",
    "            ax2.set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "            ax2.set_ylabel('Loss', fontsize=12)\n",
    "            ax2.set_xlabel('Epoch', fontsize=12)\n",
    "            ax2.legend(loc='upper right')\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(\"pictures/motor_training_curves.png\", dpi=150)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f52a53-7363-4b79-b39a-dc83d749eb19",
   "metadata": {},
   "source": [
    "# Dataset Paths, Splitting, and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8cc183-6e26-43ee-a442-c139037f7c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths for user's dataset\n",
    "DATASET_DIR = os.path.join(\"datasets\", \"Grey\", \"motor\")\n",
    "MODELS_DIR = os.path.join(\"models\", \"Grey\")\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(\"pictures\", exist_ok=True)\n",
    "\n",
    "split_data(starting_dir=DATASET_DIR, shuffle=True, splitting_percentage=(70, 20, 10), division_factor=0, coupling=False)\n",
    "\n",
    "# loading dataset\n",
    "tmp_train_X, train_y = load_data(starting_dir=\"training_data\", shuffle=True, balance=True)\n",
    "tmp_validation_X, validation_y = load_data(starting_dir=\"validation_data\", shuffle=True, balance=True)\n",
    "\n",
    "print(f\"Train samples: {len(tmp_train_X)}, Val samples: {len(tmp_validation_X)}\")\n",
    "\n",
    "# cleaning the raw data (bandpass 8-30 Hz for motor imagery)\n",
    "train_X, fft_train_X = preprocess_raw_eeg(tmp_train_X, lowcut=8, highcut=30, coi3order=0)\n",
    "validation_X, fft_validation_X = preprocess_raw_eeg(tmp_validation_X, lowcut=8, highcut=30, coi3order=0)\n",
    "\n",
    "# check_other_classifiers(train_X, train_y, validation_X, validation_y)\n",
    "\n",
    "# reshaping\n",
    "train_X = train_X.reshape((len(train_X), len(train_X[0]), len(train_X[0, 0]), 1))\n",
    "validation_X = validation_X.reshape((len(validation_X), len(validation_X[0]), len(validation_X[0, 0]), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7420744-2f92-4ba7-a4c0-d1d231be781b",
   "metadata": {},
   "source": [
    "# Model Selection & Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b9793f-77bc-4373-b00a-f176b5c05181",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EEGNet(nb_classes=len(ACTIONS), Chans=8, Samples=250)\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='nadam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "keras.utils.plot_model(model, \"pictures/net.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38db7dca-5a8d-4bad-a293-34303565df6e",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751bf660-cca0-4463-a05d-a9b6eb46ff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 500\n",
    "fit_and_save(model, epochs, train_X, train_y, validation_X, validation_y, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce5c818-c387-477f-bab3-d0bff1b31465",
   "metadata": {},
   "source": [
    "# 4. Test Using Real-Time-Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e47bd8-8114-4acb-b55b-0c2124ba83d5",
   "metadata": {},
   "source": [
    "# Imports and Globals\n",
    "- Introduces all Python modules used in the realtime BCI system.\n",
    "- Clarifies why each import is needed.\n",
    "- Sets expectations for dependencies and external libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc73d6cc-77cf-41dd-b9f9-376aafd58685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is intended for OpenBCI Cyton Board\n",
    "# For other boards: https://brainflow.readthedocs.io\n",
    "\n",
    "from functions import ACTIONS, preprocess_raw_eeg\n",
    "\n",
    "from brainflow import BoardShim, BrainFlowInputParams, BoardIds\n",
    "from matplotlib import pyplot as plt\n",
    "from timeit import default_timer as timer\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import threading\n",
    "import argparse\n",
    "import time\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed9cc95-a85a-43de-b115-32ac699f457d",
   "metadata": {},
   "source": [
    "# Shared Memory Class (Thread Communication) & Graphical Interface (GUI) Class\n",
    "Shared Memory Class holds two values:\n",
    "- sample: the most recent 1-second EEG window (8×250)\n",
    "- key: keyboard input used for quitting the GUI\n",
    "\n",
    "Avoids using global variables for thread safety.\n",
    "\n",
    "Synchronization between threads is handled using a shared mutex lock.\n",
    "\n",
    "GUI Class:\n",
    "- Built using OpenCV for lightweight 2D graphics.\n",
    "- Displays a simple box on a colored background that moves left/right.\n",
    "\n",
    "Movement is controlled by the model’s predictions:\n",
    "- “left” → box moves left\n",
    "- “right” → box moves right\n",
    "- Has a central horizontal and vertical line as visual anchors.\n",
    "- Uses random colors for box/lines to visually differentiate elements.\n",
    "- Resets automatically after a certain number of frames (count_down)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0d53e32-91e8-458c-ac2a-c763690a1d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shared:\n",
    "    def __init__(self):\n",
    "        self.sample = None\n",
    "        self.key = None\n",
    "\n",
    "\n",
    "class GraphicalInterface:\n",
    "    def __init__(self, WIDTH=500, HEIGHT=500, SQ_SIZE=40, MOVE_SPEED=5):\n",
    "        self.WIDTH = WIDTH\n",
    "        self.HEIGHT = HEIGHT\n",
    "        self.SQ_SIZE = SQ_SIZE\n",
    "        self.MOVE_SPEED = MOVE_SPEED\n",
    "\n",
    "        self.square = {'x1': int(WIDTH / 2 - SQ_SIZE / 2),\n",
    "                       'x2': int(WIDTH / 2 + SQ_SIZE / 2),\n",
    "                       'y1': int(HEIGHT / 2 - SQ_SIZE / 2),\n",
    "                       'y2': int(HEIGHT / 2 + SQ_SIZE / 2)}\n",
    "\n",
    "        self.box = np.ones((self.SQ_SIZE, self.SQ_SIZE, 3)) * np.random.uniform(size=(3,))\n",
    "        self.horizontal_line = np.ones((HEIGHT, 10, 3)) * np.random.uniform(size=(3,))\n",
    "        self.vertical_line = np.ones((10, WIDTH, 3)) * np.random.uniform(size=(3,))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef138cf-956f-4e25-a43a-f2efe5449944",
   "metadata": {},
   "source": [
    "# Acquisition Thread (Pulling Cyton Samples)\n",
    "- Runs in a dedicated thread.\n",
    "- Continuously reads 250 samples (1 second) from the Cyton board buffer.\n",
    "- Uses BoardShim.get_current_board_data for overlapping windows.\n",
    "- Extracts EEG channel data from all 8 Cyton channels.\n",
    "- Writes the newest EEG window into shared_vars.sample.\n",
    "- Uses a mutex lock to ensure safe shared memory access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd3cd0f3-ce59-46b2-807b-539139bf2813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquire_signals():\n",
    "    count = 0\n",
    "    while True:\n",
    "        with mutex:\n",
    "            if count == 0:\n",
    "                time.sleep(2)\n",
    "                count += 1\n",
    "            time.sleep(0.5)\n",
    "\n",
    "            data = board.get_current_board_data(250)\n",
    "\n",
    "            eeg_channels = BoardShim.get_eeg_channels(BoardIds.CYTON_BOARD.value)\n",
    "            sample = [data[ch] for ch in eeg_channels]\n",
    "            shared_vars.sample = np.array(sample)\n",
    "\n",
    "            if shared_vars.key == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "        time.sleep(0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737a8e1f-17ae-4a63-b803-8b635899db7c",
   "metadata": {},
   "source": [
    "# Compute Thread (Inference + GUI Control)\n",
    "How it works:\n",
    "- Runs in parallel with the acquisition thread.\n",
    "- Loads the trained Keras model at startup.\n",
    "\n",
    "Each iteration:\n",
    "1. Reads the newest EEG window from shared_vars.sample\n",
    "2. Preprocesses it using the same filters used during training\n",
    "3. Runs the model to obtain class probabilities\n",
    "4. Smooths predictions using an exponential moving average (EMA)\n",
    "5. Applies confidence thresholding\n",
    "6. Updates GUI movement accordingly\n",
    "- Prevents jittery or unstable predictions using the EMA filter.\n",
    "- Displays real-time FPS for performance monitoring.\n",
    "- Resets the GUI after 100 cycles for a consistent visual experience.\n",
    "- Exits immediately if the user presses “q”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c46794ff-2f14-4e55-abcc-24806842cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_signals():\n",
    "    MODEL_NAME = \"models/Grey/85.0-76epoch-1763074954-loss-0.43.keras\"\n",
    "    model = keras.models.load_model(MODEL_NAME)\n",
    "\n",
    "    count_down = 100\n",
    "    EMA = [-1, -1]\n",
    "    alpha = 0.4\n",
    "    gui = GraphicalInterface()\n",
    "    first_run = True\n",
    "\n",
    "    while True:\n",
    "        with mutex:\n",
    "\n",
    "            if count_down == 0:\n",
    "                gui = GraphicalInterface()\n",
    "                count_down = 100\n",
    "\n",
    "            env = np.zeros((gui.WIDTH, gui.HEIGHT, 3))\n",
    "\n",
    "            nn_input, _ = preprocess_raw_eeg(\n",
    "                shared_vars.sample.reshape((1, 8, 250)),\n",
    "                fs=250, lowcut=8, highcut=30, coi3order=0\n",
    "            )\n",
    "            nn_input = nn_input.reshape((1, 8, 250, 1))\n",
    "\n",
    "            nn_out = model.predict(nn_input, verbose=0)[0]\n",
    "\n",
    "            if EMA[0] == -1:\n",
    "                EMA = nn_out.copy()\n",
    "            else:\n",
    "                EMA = alpha * nn_out + (1 - alpha) * np.array(EMA)\n",
    "\n",
    "            predicted_action = ACTIONS[np.argmax(EMA)]\n",
    "            conf = EMA[np.argmax(EMA)]\n",
    "\n",
    "            if conf > 0.67:\n",
    "                if predicted_action == \"left\":\n",
    "                    gui.square['x1'] -= gui.MOVE_SPEED\n",
    "                    gui.square['x2'] -= gui.MOVE_SPEED\n",
    "                elif predicted_action == \"right\":\n",
    "                    gui.square['x1'] += gui.MOVE_SPEED\n",
    "                    gui.square['x2'] += gui.MOVE_SPEED\n",
    "\n",
    "            count_down -= 1\n",
    "\n",
    "            # Draw GUI\n",
    "            env[:, gui.HEIGHT // 2 - 5:gui.HEIGHT // 2 + 5] = gui.horizontal_line\n",
    "            env[gui.WIDTH // 2 - 5:gui.WIDTH // 2 + 5, :] = gui.vertical_line\n",
    "\n",
    "            env[\n",
    "                gui.square['y1']:gui.square['y2'],\n",
    "                gui.square['x1']:gui.square['x2']\n",
    "            ] = gui.box\n",
    "\n",
    "            cv2.imshow('EEG BCI', env)\n",
    "\n",
    "            if first_run:\n",
    "                first_run = False\n",
    "                start = timer()\n",
    "            else:\n",
    "                end = timer()\n",
    "                print(\"\\rFPS:\", 1 / (end - start + 1e-6), end='')\n",
    "                start = timer()\n",
    "\n",
    "            shared_vars.key = cv2.waitKey(1) & 0xFF\n",
    "            if shared_vars.key == ord(\"q\"):\n",
    "                cv2.destroyAllWindows()\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b14c7cb-ea17-4614-8a42-50bf275db550",
   "metadata": {},
   "source": [
    "# Main Execution Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4576b5c0-486f-4c4d-947f-79774434ef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = BrainFlowInputParams()\n",
    "params.serial_port = \"COM3\"\n",
    "\n",
    "board = BoardShim(BoardIds.CYTON_BOARD.value, params)\n",
    "board.prepare_session()\n",
    "\n",
    "shared_vars = Shared()\n",
    "mutex = threading.Lock()\n",
    "\n",
    "board.start_stream()\n",
    "\n",
    "acquisition = threading.Thread(target=acquire_signals)\n",
    "computing = threading.Thread(target=compute_signals)\n",
    "\n",
    "acquisition.start()\n",
    "computing.start()\n",
    "\n",
    "acquisition.join()\n",
    "computing.join()\n",
    "\n",
    "board.stop_stream()\n",
    "board.release_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69b0f6d-c97e-440b-a567-1bf8c28a4e7c",
   "metadata": {},
   "source": [
    "# 5. Move Wheelchair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a233ab-1e9a-44db-a025-42419d3edd2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
